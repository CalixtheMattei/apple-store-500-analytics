{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 \u00b7 Sentiment & Topic Analysis\n",
        "\n",
        "Robust multilingual sentiment and topic extraction for App Review Insights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Requirements\n",
        "\n",
        "Optional pip installs (run manually in a cell if needed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt\n",
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download fr_core_news_sm\n",
        "# !python -m spacy download de_core_news_sm\n",
        "# !python -m spacy download es_core_news_sm\n",
        "# !python -m spacy download it_core_news_sm\n",
        "# !python -m spacy download sv_core_news_sm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports & configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from ml.pipeline import sentiment_topics as st\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
        "tqdm.pandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "CONFIG_PATH = Path('config/apps.json')\n",
        "DATA_PATH = Path('data/processed_reviews.csv')\n",
        "OUTPUT_DIR = Path('data/output')\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "with CONFIG_PATH.open() as fh:\n",
        "    app_config = json.load(fh)\n",
        "COUNTRIES = app_config.get('countries', list(st.DEFAULT_COUNTRY_LANGUAGE_MAP.keys()))\n",
        "COUNTRY_LANGUAGE_MAP = {**st.DEFAULT_COUNTRY_LANGUAGE_MAP}\n",
        "COUNTRY_LANGUAGE_MAP.update({c: COUNTRY_LANGUAGE_MAP.get(c, st.DEFAULT_COUNTRY_LANGUAGE_MAP.get(c, 'en')) for c in COUNTRIES})\n",
        "COUNTRY_LANGUAGE_MAP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load processed reviews\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "start_time = time.perf_counter()\n",
        "reviews_df = pd.read_csv(DATA_PATH)\n",
        "if reviews_df.empty:\n",
        "    raise ValueError('No reviews found in data/processed_reviews.csv')\n",
        "required_cols = {'id', 'app_name', 'country', 'cleaned_content', 'rating', 'review_date'}\n",
        "missing = required_cols - set(reviews_df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f'Missing required columns: {missing}')\n",
        "reviews_df = reviews_df.dropna(subset=['cleaned_content']).copy()\n",
        "reviews_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detect languages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "reviews_df['detected_language'] = st.detect_languages(reviews_df, COUNTRY_LANGUAGE_MAP)\n",
        "reviews_df['detected_language'].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load spaCy language pipelines\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "models, lang_resolution = st.load_spacy_models(reviews_df['detected_language'].unique(), COUNTRY_LANGUAGE_MAP)\n",
        "sorted(models.keys())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split reviews into sentences\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "sentences_df = st.split_sentences(reviews_df, models, lang_resolution)\n",
        "if sentences_df.empty:\n",
        "    raise ValueError('Sentence splitting produced no data')\n",
        "sentences_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run multilingual sentiment analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "sentiment_scores = st.run_sentiment(sentences_df, batch_size=BATCH_SIZE)\n",
        "sentences_with_sentiment = sentences_df.join(sentiment_scores, how='left')\n",
        "sentences_with_sentiment.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extract topics per sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "structured_rows = []\n",
        "reviews_by_id = reviews_df.set_index('id')\n",
        "for review_id, group in tqdm(sentences_with_sentiment.groupby('id'), desc='Aggregate reviews'):\n",
        "    review_meta = reviews_by_id.loc[review_id]\n",
        "    sentences_list = group['sentence'].tolist()\n",
        "    sentiments_list = group['sentiment_label'].fillna('neutral').tolist()\n",
        "    language = review_meta['detected_language']\n",
        "    topics_per_sentence = st.extract_topics(sentences_list, language, options={'top_n': 5, 'ngram_range': (1, 2), 'diversity': 0.6})\n",
        "    review_topics = st.merge_topics(topics_per_sentence, limit=5)\n",
        "    details = st.build_details(sentences_list, sentiments_list, topics_per_sentence)\n",
        "    label, score = st.aggregate_sentiment(sentiments_list)\n",
        "    structured_rows.append({\n",
        "        'id': review_id,\n",
        "        'app_name': review_meta['app_name'],\n",
        "        'country': review_meta['country'],\n",
        "        'language': language,\n",
        "        'rating': review_meta.get('rating'),\n",
        "        'cleaned_content': review_meta.get('cleaned_content'),\n",
        "        'sentiment_label': label,\n",
        "        'sentiment_score': score,\n",
        "        'topics': review_topics,\n",
        "        'details': details,\n",
        "        'review_date': review_meta.get('review_date'),\n",
        "    })\n",
        "structured_df = pd.DataFrame(structured_rows)\n",
        "structured_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NotebookLM export & topic summary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "structured_df['notebook_sentence'] = structured_df.apply(st.make_notebook_sentence, axis=1)\n",
        "notebook_df = structured_df[['id', 'app_name', 'country', 'language', 'sentiment_label', 'sentiment_score', 'notebook_sentence']].copy()\n",
        "topic_summary = (\n",
        "    structured_df.explode('topics')\n",
        "    .dropna(subset=['topics'])\n",
        "    .groupby(['app_name', 'country', 'topics', 'sentiment_label'], as_index=False)\n",
        "    .agg(review_count=('id', 'count'))\n",
        "    .rename(columns={'topics': 'topic'})\n",
        ")\n",
        "structured_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export CSV artifacts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "st.write_csvs(structured_df.drop(columns=['notebook_sentence']), notebook_df, topic_summary, OUTPUT_DIR)\n",
        "sentiment_counts = structured_df['sentiment_label'].value_counts()\n",
        "print('Sentiment distribution:')\n",
        "print(sentiment_counts)\n",
        "print('Sample NotebookLM sentences:')\n",
        "for example in notebook_df['notebook_sentence'].head(3):\n",
        "    print('-', example)\n",
        "elapsed = time.perf_counter() - start_time\n",
        "print(f'Total runtime: {elapsed:.2f}s')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}